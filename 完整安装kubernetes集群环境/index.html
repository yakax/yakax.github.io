<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=X-UA-Compatible content="IE=edge, chrome=1"><title>完整安装kubernetes集群环境 - yakax</title><meta name=Description content><meta property="og:url" content="https://yakax.github.io/%E5%AE%8C%E6%95%B4%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83/">
<meta property="og:site_name" content="yakax"><meta property="og:title" content="完整安装kubernetes集群环境"><meta property="og:description" content="1.准备基础环境 我们将使用kubeadm部署3个节点的 Kubernetes Cluster
节点详细信息：
节点主机名 节点IP 节点角色 操作系统 节点配置 k8s-master 192.168.217.131 master CentOS7.6 2C4G k8s-node1 192.168.217.132 node CentOS7.6 2C4G k8s-node2 192.168.217.133 node CentOS7.6 2C4G 节点组件分布： Master 和 Node 节点由于分工不一样，所以安装的服务不同，最终安装完毕，Master 和 Node 启动的核心服务分别如下：
Master节点 Node节点 kube-apiserver kube-flannel kube-scheduler other apps kube-proxy — etcd — coredns — kube-flannel — 无特殊说明以下操作在所有节点执行： "><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-01-14T00:00:00+00:00"><meta property="article:modified_time" content="2019-01-14T00:00:00+00:00"><meta property="article:tag" content="Kubernetes"><meta property="og:image" content="https://yakax.github.io/images/1.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yakax.github.io/images/1.png"><meta name=twitter:title content="完整安装kubernetes集群环境"><meta name=twitter:description content="1.准备基础环境
我们将使用kubeadm部署3个节点的 Kubernetes Cluster
节点详细信息：



节点主机名
节点IP
节点角色
操作系统
节点配置




k8s-master
192.168.217.131
master
CentOS7.6
2C4G


k8s-node1
192.168.217.132
node
CentOS7.6
2C4G


k8s-node2
192.168.217.133
node
CentOS7.6
2C4G



节点组件分布：
Master 和 Node 节点由于分工不一样，所以安装的服务不同，最终安装完毕，Master 和 Node 启动的核心服务分别如下：



Master节点
Node节点




kube-apiserver
kube-flannel


kube-scheduler
other apps


kube-proxy
&mdash;


etcd
&mdash;


coredns
&mdash;


kube-flannel
&mdash;


无特殊说明以下操作在所有节点执行：



"><meta name=application-name content="yakax"><meta name=apple-mobile-web-app-title content="yakax"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><script>(function(e,t,n,s,o,i,a){e.DaoVoiceObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,i.charset="utf-8",a.parentNode.insertBefore(i,a)})(window,document,"script",("https:"==document.location.protocol?"https:":"http:")+"//widget.daovoice.io/widget/af744044.js","daovoice"),daovoice("init",{app_id:"af744044"}),daovoice("update")</script><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://yakax.github.io/%E5%AE%8C%E6%95%B4%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83/><link rel=prev href=https://yakax.github.io/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/><link rel=next href=https://yakax.github.io/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"完整安装kubernetes集群环境","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/yakax.github.io\/%E5%AE%8C%E6%95%B4%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83\/"},"image":["https:\/\/yakax.github.io\/images\/avatar.png"],"genre":"posts","keywords":"kubernetes","wordcount":9009,"url":"https:\/\/yakax.github.io\/%E5%AE%8C%E6%95%B4%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83\/","datePublished":"2019-01-14T00:00:00+00:00","dateModified":"2019-01-14T00:00:00+00:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"yakax","logo":"https:\/\/yakax.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"yakax"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=yakax><span class=header-title-pre><i class='fas fa-crosshairs fa-sm'></i></span><span id=id-1 class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>所有文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><a class=menu-item href=https://github.com/yakax title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i> </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fas fa-search fa-fw"></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fas fa-times-circle fa-fw"></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=yakax><span class=header-title-pre><i class='fas fa-crosshairs fa-sm'></i></span><span id=id-2 class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fas fa-search fa-fw"></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fas fa-times-circle fa-fw"></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></div><a class=menu-item href=/posts/ title>所有文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a class=menu-item href=https://github.com/yakax title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i></a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">完整安装kubernetes集群环境</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>yakax</a></span>&nbsp;<span class=post-category>收录于 <a href=/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/><i class="far fa-folder fa-fw"></i>云原生</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2019-01-14>2019-01-14</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 9009 字&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 18 分钟&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#1准备基础环境>1.准备基础环境</a></li><li><a href=#2部署master节点>2.部署master节点</a></li><li><a href=#3部署workernode节点>3.部署worker(node)节点</a></li><li><a href=#测试集群各个组件>测试集群各个组件</a></li><li><a href=#pod调度到master节点可以不做>Pod调度到Master节点（可以不做）</a></li><li><a href=#kube-proxy开启ipvs>kube-proxy开启ipvs</a></li></ul></nav></div></div><div class=content id=content><h2 id=1准备基础环境>1.准备基础环境</h2><p>我们将使用kubeadm部署3个节点的 Kubernetes Cluster</p><p><strong>节点详细信息：</strong></p><table><thead><tr><th>节点主机名</th><th>节点IP</th><th>节点角色</th><th>操作系统</th><th>节点配置</th></tr></thead><tbody><tr><td>k8s-master</td><td>192.168.217.131</td><td>master</td><td>CentOS7.6</td><td>2C4G</td></tr><tr><td>k8s-node1</td><td>192.168.217.132</td><td>node</td><td>CentOS7.6</td><td>2C4G</td></tr><tr><td>k8s-node2</td><td>192.168.217.133</td><td>node</td><td>CentOS7.6</td><td>2C4G</td></tr></tbody></table><p><strong>节点组件分布：</strong>
Master 和 Node 节点由于分工不一样，所以安装的服务不同，最终安装完毕，Master 和 Node 启动的核心服务分别如下：</p><table><thead><tr><th>Master节点</th><th>Node节点</th></tr></thead><tbody><tr><td>kube-apiserver</td><td>kube-flannel</td></tr><tr><td>kube-scheduler</td><td>other apps</td></tr><tr><td>kube-proxy</td><td>&mdash;</td></tr><tr><td>etcd</td><td>&mdash;</td></tr><tr><td>coredns</td><td>&mdash;</td></tr><tr><td>kube-flannel</td><td>&mdash;</td></tr><tr><td>无特殊说明以下操作在所有节点执行：</td><td></td></tr></tbody></table><p><strong>修改主机名(master与node都要执行)：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#master节点:
</span></span><span class=line><span class=cl>hostnamectl set-hostname k8s-master
</span></span><span class=line><span class=cl>#node1节点：
</span></span><span class=line><span class=cl>hostnamectl set-hostname k8s-node1
</span></span><span class=line><span class=cl>#node2节点:
</span></span><span class=line><span class=cl>hostnamectl set-hostname k8s-node2
</span></span></code></pre></td></tr></table></div></div><p><strong>基本配置(master与node都要执行)：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#修改/etc/hosts文件
</span></span><span class=line><span class=cl>cat &gt;&gt; /etc/hosts &lt;&lt; EOF
</span></span><span class=line><span class=cl>192.168.217.131 k8s-master
</span></span><span class=line><span class=cl>192.168.217.132 k8s-node1
</span></span><span class=line><span class=cl>192.168.217.133 k8s-node2
</span></span><span class=line><span class=cl>EOF
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#关闭防火墙和selinux
</span></span><span class=line><span class=cl>systemctl stop firewalld &amp;&amp; systemctl disable firewalld
</span></span><span class=line><span class=cl>sed -i &#39;s/^SELINUX=enforcing$/SELINUX=disabled/&#39; /etc/selinux/config &amp;&amp; setenforce 0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#关闭swap
</span></span><span class=line><span class=cl>swapoff -a
</span></span><span class=line><span class=cl>yes | cp /etc/fstab /etc/fstab_bak
</span></span><span class=line><span class=cl>cat /etc/fstab_bak |grep -v swap &gt; /etc/fstab
</span></span></code></pre></td></tr></table></div></div><p><strong>配置时间同步(master与node都要执行):</strong>
使用chrony同步时间，配置master节点与网络NTP服务器同步时间，所有node节点与master节点同步时间。
配置master节点：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#安装chrony：
</span></span><span class=line><span class=cl>yum install -y chrony
</span></span><span class=line><span class=cl>#注释默认ntp服务器
</span></span><span class=line><span class=cl>sed -i &#39;s/^server/#&amp;/&#39; /etc/chrony.conf
</span></span><span class=line><span class=cl>#指定上游公共 ntp 服务器，并允许其他节点同步时间
</span></span><span class=line><span class=cl>cat &gt;&gt; /etc/chrony.conf &lt;&lt; EOF
</span></span><span class=line><span class=cl>server 0.asia.pool.ntp.org iburst
</span></span><span class=line><span class=cl>server 1.asia.pool.ntp.org iburst
</span></span><span class=line><span class=cl>server 2.asia.pool.ntp.org iburst
</span></span><span class=line><span class=cl>server 3.asia.pool.ntp.org iburst
</span></span><span class=line><span class=cl>allow all
</span></span><span class=line><span class=cl>EOF
</span></span><span class=line><span class=cl>#重启chronyd服务并设为开机启动：
</span></span><span class=line><span class=cl>systemctl enable chronyd &amp;&amp; systemctl restart chronyd
</span></span><span class=line><span class=cl>#开启网络时间同步功能
</span></span><span class=line><span class=cl>timedatectl set-ntp true
</span></span></code></pre></td></tr></table></div></div><p>配置所有node节点：(注意修改master IP地址)</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#安装chrony：
</span></span><span class=line><span class=cl>yum install -y chrony
</span></span><span class=line><span class=cl>#注释默认服务器
</span></span><span class=line><span class=cl>sed -i &#39;s/^server/#&amp;/&#39; /etc/chrony.conf
</span></span><span class=line><span class=cl>#指定内网 master节点为上游NTP服务器
</span></span><span class=line><span class=cl>echo server 192.168.217.131 iburst &gt;&gt; /etc/chrony.conf
</span></span><span class=line><span class=cl>#重启服务并设为开机启动：
</span></span><span class=line><span class=cl>systemctl enable chronyd &amp;&amp; systemctl restart chronyd
</span></span></code></pre></td></tr></table></div></div><p>所有节点执行chronyc sources命令，查看存在以^*开头的行，说明已经与服务器时间同步</p><p><strong>设置网桥包经过iptalbes(master与node都要执行)</strong>
RHEL / CentOS 7上的一些用户报告了由于iptables被绕过而导致流量路由不正确的问题。创建/etc/sysctl.d/k8s.conf文件，添加如下内容：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
</span></span><span class=line><span class=cl>vm.swappiness = 0
</span></span><span class=line><span class=cl>net.bridge.bridge-nf-call-ip6tables = 1
</span></span><span class=line><span class=cl>net.bridge.bridge-nf-call-iptables = 1
</span></span><span class=line><span class=cl>net.ipv4.ip_forward = 1
</span></span><span class=line><span class=cl>EOF
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 使配置生效
</span></span><span class=line><span class=cl>modprobe br_netfilter
</span></span><span class=line><span class=cl>sysctl -p /etc/sysctl.d/k8s.conf
</span></span></code></pre></td></tr></table></div></div><p><strong>kube-proxy开启ipvs的前提条件(master与node都要执行)</strong>
由于ipvs已经加入到了内核的主干，所以为kube-proxy开启ipvs的前提需要加载以下的内核模块：
在所有的Kubernetes节点执行以下脚本:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cat &gt; /etc/sysconfig/modules/ipvs.modules <span class=s>&lt;&lt;EOF
</span></span></span><span class=line><span class=cl><span class=s>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- ip_vs
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- ip_vs_rr
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- ip_vs_wrr
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- ip_vs_sh
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- nf_conntrack_ipv4
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#执行脚本</span>
</span></span><span class=line><span class=cl>chmod <span class=m>755</span> /etc/sysconfig/modules/ipvs.modules <span class=o>&amp;&amp;</span> bash /etc/sysconfig/modules/ipvs.modules <span class=o>&amp;&amp;</span> lsmod <span class=p>|</span> grep -e ip_vs -e nf_conntrack_ipv4
</span></span></code></pre></td></tr></table></div></div><p>上面脚本创建了/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。 使用lsmod | grep -e ip_vs -e nf_conntrack_ipv4命令查看是否已经正确加载所需的内核模块。
接下来还需要确保各个节点上已经安装了ipset软件包。 为了便于查看ipvs的代理规则，最好安装一下管理工具ipvsadm。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># yum install ipset ipvsadm -y
</span></span></code></pre></td></tr></table></div></div><p><strong>安装Docker（这个可以提前自己安装&ndash;也可以选用我之前的方案离线安装+阿里云镜像加速）</strong>
Kubernetes默认的容器运行时仍然是Docker，使用的是kubelet中内置dockershim CRI实现。需要注意的是，Kubernetes 1.13最低支持的Docker版本是1.11.1，最高支持是18.06，而Docker最新版本已经是18.09了，故我们安装时需要指定版本为18.06.1-ce。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#配置docker yum源
</span></span><span class=line><span class=cl>yum-config-manager \
</span></span><span class=line><span class=cl>    --add-repo \
</span></span><span class=line><span class=cl>http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#安装指定版本，这里安装18.06
</span></span><span class=line><span class=cl>yum list docker-ce --showduplicates | sort -r
</span></span><span class=line><span class=cl>yum install -y docker-ce-18.06.1.ce-3.el7
</span></span><span class=line><span class=cl>systemctl start docker &amp;&amp; systemctl enable docker
</span></span></code></pre></td></tr></table></div></div><p>脚本安装docker-ce并配置daocloud镜像加速(可选)：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>bash Install_docker-ce.sh
</span></span></code></pre></td></tr></table></div></div><p><strong>安装kubeadm、kubelet、kubectl(master与node都要执行)</strong>
官方安装文档可以参考：
<a href=https://kubernetes.io/docs/setup/independent/install-kubeadm/ target=_blank rel="noopener noreffer">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></p><ul><li>kubelet 在群集中所有节点上运行的核心组件, 用来执行如启动pods和containers等操作。</li><li>kubeadm 引导启动k8s集群的命令行工具，用于初始化 Cluster。</li><li>kubectl 是 Kubernetes 命令行工具。通过 kubectl 可以部署和管理应用，查看各种资源，创建、删除和更新各种组件。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#配置kubernetes.repo的源，由于官方源国内无法访问，这里使用阿里云yum源
</span></span><span class=line><span class=cl>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span><span class=line><span class=cl>[kubernetes]
</span></span><span class=line><span class=cl>name=Kubernetes
</span></span><span class=line><span class=cl>baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
</span></span><span class=line><span class=cl>enabled=1
</span></span><span class=line><span class=cl>gpgcheck=1
</span></span><span class=line><span class=cl>repo_gpgcheck=1
</span></span><span class=line><span class=cl>gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span></span><span class=line><span class=cl>EOF
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#在所有节点上安装指定版本 kubelet、kubeadm 和 kubectl
</span></span><span class=line><span class=cl>yum install -y kubelet-1.13.1 kubeadm-1.13.1 kubectl-1.13.1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#启动kubelet服务
</span></span><span class=line><span class=cl>systemctl enable kubelet &amp;&amp; systemctl start kubelet
</span></span></code></pre></td></tr></table></div></div><h2 id=2部署master节点>2.部署master节点</h2><p>完整的官方文档可以参考：
<a href=https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/ target=_blank rel="noopener noreffer">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a>
<a href=https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/ target=_blank rel="noopener noreffer">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/</a>
<strong>Master节点执行初始化</strong>：</p><p>注意这里执行初始化用到了- -image-repository选项，指定初始化需要的镜像源从阿里云镜像仓库拉取。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubeadm init \
</span></span><span class=line><span class=cl>    --apiserver-advertise-address=192.168.217.131 \
</span></span><span class=line><span class=cl>    --image-repository registry.aliyuncs.com/google_containers \
</span></span><span class=line><span class=cl>    --kubernetes-version v1.13.1 \
</span></span><span class=line><span class=cl>    --pod-network-cidr=10.244.0.0/16
</span></span></code></pre></td></tr></table></div></div><p><strong>初始化命令说明：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>--apiserver-advertise-address
</span></span></code></pre></td></tr></table></div></div><p>指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个 interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的 interface。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>--pod-network-cidr
</span></span></code></pre></td></tr></table></div></div><p>指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对 –pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用 flannel 网络方案，必须设置成这个 CIDR。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>--image-repository
</span></span></code></pre></td></tr></table></div></div><p>Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问 gcr.io，在1.13版本中我们可以增加–image-repository参数，默认值是 k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com/google_containers。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>--kubernetes-version=v1.13.1  
</span></span></code></pre></td></tr></table></div></div><p>关闭版本探测，因为它的默认值是stable-1，会导致下载最新版本，这里固定版本1.13.1的</p><p><strong>初始化过程如下：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span> <span class=o>~</span><span class=p>]</span><span class=c1># kubeadm init \</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=o>--</span><span class=n>image</span><span class=o>-</span><span class=n>repository</span> <span class=n>registry</span><span class=o>.</span><span class=n>aliyuncs</span><span class=o>.</span><span class=n>com</span><span class=o>/</span><span class=n>google_containers</span> \
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=o>--</span><span class=n>kubernetes</span><span class=o>-</span><span class=n>version</span> <span class=n>v1</span><span class=o>.</span><span class=mf>13.1</span> \
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=o>--</span><span class=n>pod</span><span class=o>-</span><span class=n>network</span><span class=o>-</span><span class=n>cidr</span><span class=o>=</span><span class=mf>10.244</span><span class=o>.</span><span class=mf>0.0</span><span class=o>/</span><span class=mi>16</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>init</span><span class=p>]</span> <span class=n>Using</span> <span class=n>Kubernetes</span> <span class=n>version</span><span class=p>:</span> <span class=n>v1</span><span class=o>.</span><span class=mf>13.1</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>Running</span> <span class=n>pre</span><span class=o>-</span><span class=n>flight</span> <span class=n>checks</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>Pulling</span> <span class=n>images</span> <span class=n>required</span> <span class=k>for</span> <span class=n>setting</span> <span class=n>up</span> <span class=n>a</span> <span class=n>Kubernetes</span> <span class=n>cluster</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>This</span> <span class=n>might</span> <span class=n>take</span> <span class=n>a</span> <span class=n>minute</span> <span class=ow>or</span> <span class=n>two</span><span class=p>,</span> <span class=n>depending</span> <span class=n>on</span> <span class=n>the</span> <span class=n>speed</span> <span class=n>of</span> <span class=n>your</span> <span class=n>internet</span> <span class=n>connection</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>You</span> <span class=n>can</span> <span class=n>also</span> <span class=n>perform</span> <span class=n>this</span> <span class=n>action</span> <span class=ow>in</span> <span class=n>beforehand</span> <span class=n>using</span> <span class=s1>&#39;kubeadm config images pull&#39;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Writing</span> <span class=n>kubelet</span> <span class=n>environment</span> <span class=n>file</span> <span class=n>with</span> <span class=n>flags</span> <span class=n>to</span> <span class=n>file</span> <span class=s2>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Writing</span> <span class=n>kubelet</span> <span class=n>configuration</span> <span class=n>to</span> <span class=n>file</span> <span class=s2>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Activating</span> <span class=n>the</span> <span class=n>kubelet</span> <span class=n>service</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Using</span> <span class=n>certificateDir</span> <span class=n>folder</span> <span class=s2>&#34;/etc/kubernetes/pki&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;etcd/ca&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;etcd/healthcheck-client&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;apiserver-etcd-client&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;etcd/server&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>etcd</span><span class=o>/</span><span class=n>server</span> <span class=n>serving</span> <span class=n>cert</span> <span class=n>is</span> <span class=n>signed</span> <span class=k>for</span> <span class=n>DNS</span> <span class=n>names</span> <span class=p>[</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span> <span class=n>localhost</span><span class=p>]</span> <span class=ow>and</span> <span class=n>IPs</span> <span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>217.131</span> <span class=mf>127.0</span><span class=o>.</span><span class=mf>0.1</span> <span class=p>::</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;etcd/peer&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>etcd</span><span class=o>/</span><span class=n>peer</span> <span class=n>serving</span> <span class=n>cert</span> <span class=n>is</span> <span class=n>signed</span> <span class=k>for</span> <span class=n>DNS</span> <span class=n>names</span> <span class=p>[</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span> <span class=n>localhost</span><span class=p>]</span> <span class=ow>and</span> <span class=n>IPs</span> <span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>217.131</span> <span class=mf>127.0</span><span class=o>.</span><span class=mf>0.1</span> <span class=p>::</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;ca&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;apiserver&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>apiserver</span> <span class=n>serving</span> <span class=n>cert</span> <span class=n>is</span> <span class=n>signed</span> <span class=k>for</span> <span class=n>DNS</span> <span class=n>names</span> <span class=p>[</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span> <span class=n>kubernetes</span> <span class=n>kubernetes</span><span class=o>.</span><span class=n>default</span> <span class=n>kubernetes</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=n>svc</span> <span class=n>kubernetes</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=n>svc</span><span class=o>.</span><span class=n>cluster</span><span class=o>.</span><span class=n>local</span><span class=p>]</span> <span class=ow>and</span> <span class=n>IPs</span> <span class=p>[</span><span class=mf>10.96</span><span class=o>.</span><span class=mf>0.1</span> <span class=mf>192.168</span><span class=o>.</span><span class=mf>217.131</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;apiserver-kubelet-client&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;front-proxy-ca&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;front-proxy-client&#34;</span> <span class=n>certificate</span> <span class=ow>and</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>certs</span><span class=p>]</span> <span class=n>Generating</span> <span class=s2>&#34;sa&#34;</span> <span class=n>key</span> <span class=ow>and</span> <span class=n>public</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Using</span> <span class=n>kubeconfig</span> <span class=n>folder</span> <span class=s2>&#34;/etc/kubernetes&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Writing</span> <span class=s2>&#34;admin.conf&#34;</span> <span class=n>kubeconfig</span> <span class=n>file</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Writing</span> <span class=s2>&#34;kubelet.conf&#34;</span> <span class=n>kubeconfig</span> <span class=n>file</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Writing</span> <span class=s2>&#34;controller-manager.conf&#34;</span> <span class=n>kubeconfig</span> <span class=n>file</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubeconfig</span><span class=p>]</span> <span class=n>Writing</span> <span class=s2>&#34;scheduler.conf&#34;</span> <span class=n>kubeconfig</span> <span class=n>file</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Using</span> <span class=n>manifest</span> <span class=n>folder</span> <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Creating</span> <span class=k>static</span> <span class=n>Pod</span> <span class=n>manifest</span> <span class=k>for</span> <span class=s2>&#34;kube-apiserver&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Creating</span> <span class=k>static</span> <span class=n>Pod</span> <span class=n>manifest</span> <span class=k>for</span> <span class=s2>&#34;kube-controller-manager&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Creating</span> <span class=k>static</span> <span class=n>Pod</span> <span class=n>manifest</span> <span class=k>for</span> <span class=s2>&#34;kube-scheduler&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>etcd</span><span class=p>]</span> <span class=n>Creating</span> <span class=k>static</span> <span class=n>Pod</span> <span class=n>manifest</span> <span class=k>for</span> <span class=n>local</span> <span class=n>etcd</span> <span class=ow>in</span> <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>wait</span><span class=o>-</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Waiting</span> <span class=k>for</span> <span class=n>the</span> <span class=n>kubelet</span> <span class=n>to</span> <span class=n>boot</span> <span class=n>up</span> <span class=n>the</span> <span class=n>control</span> <span class=n>plane</span> <span class=n>as</span> <span class=k>static</span> <span class=n>Pods</span> <span class=n>from</span> <span class=n>directory</span> <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span><span class=o>.</span> <span class=n>This</span> <span class=n>can</span> <span class=n>take</span> <span class=n>up</span> <span class=n>to</span> <span class=mi>4</span><span class=n>m0s</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>apiclient</span><span class=p>]</span> <span class=n>All</span> <span class=n>control</span> <span class=n>plane</span> <span class=n>components</span> <span class=n>are</span> <span class=n>healthy</span> <span class=n>after</span> <span class=mf>21.009858</span> <span class=n>seconds</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>uploadconfig</span><span class=p>]</span> <span class=n>storing</span> <span class=n>the</span> <span class=n>configuration</span> <span class=n>used</span> <span class=ow>in</span> <span class=n>ConfigMap</span> <span class=s2>&#34;kubeadm-config&#34;</span> <span class=ow>in</span> <span class=n>the</span> <span class=s2>&#34;kube-system&#34;</span> <span class=n>Namespace</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=p>]</span> <span class=n>Creating</span> <span class=n>a</span> <span class=n>ConfigMap</span> <span class=s2>&#34;kubelet-config-1.13&#34;</span> <span class=ow>in</span> <span class=n>namespace</span> <span class=n>kube</span><span class=o>-</span><span class=n>system</span> <span class=n>with</span> <span class=n>the</span> <span class=n>configuration</span> <span class=k>for</span> <span class=n>the</span> <span class=n>kubelets</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>cluster</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>patchnode</span><span class=p>]</span> <span class=n>Uploading</span> <span class=n>the</span> <span class=n>CRI</span> <span class=n>Socket</span> <span class=n>information</span> <span class=s2>&#34;/var/run/dockershim.sock&#34;</span> <span class=n>to</span> <span class=n>the</span> <span class=ne>Node</span> <span class=n>API</span> <span class=n>object</span> <span class=s2>&#34;k8s-master&#34;</span> <span class=n>as</span> <span class=n>an</span> <span class=n>annotation</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>mark</span><span class=o>-</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Marking</span> <span class=n>the</span> <span class=n>node</span> <span class=n>k8s</span><span class=o>-</span><span class=n>master</span> <span class=n>as</span> <span class=n>control</span><span class=o>-</span><span class=n>plane</span> <span class=n>by</span> <span class=n>adding</span> <span class=n>the</span> <span class=n>label</span> <span class=s2>&#34;node-role.kubernetes.io/master=&#39;&#39;&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>mark</span><span class=o>-</span><span class=n>control</span><span class=o>-</span><span class=n>plane</span><span class=p>]</span> <span class=n>Marking</span> <span class=n>the</span> <span class=n>node</span> <span class=n>k8s</span><span class=o>-</span><span class=n>master</span> <span class=n>as</span> <span class=n>control</span><span class=o>-</span><span class=n>plane</span> <span class=n>by</span> <span class=n>adding</span> <span class=n>the</span> <span class=n>taints</span> <span class=p>[</span><span class=n>node</span><span class=o>-</span><span class=n>role</span><span class=o>.</span><span class=n>kubernetes</span><span class=o>.</span><span class=n>io</span><span class=o>/</span><span class=n>master</span><span class=p>:</span><span class=n>NoSchedule</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Using</span> <span class=n>token</span><span class=p>:</span> <span class=mi>60</span><span class=n>syk6</span><span class=o>.</span><span class=n>vnplamkn3zhwu3s3</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstrap</span><span class=o>-</span><span class=n>token</span><span class=p>]</span> <span class=n>Configuring</span> <span class=n>bootstrap</span> <span class=n>tokens</span><span class=p>,</span> <span class=n>cluster</span><span class=o>-</span><span class=n>info</span> <span class=n>ConfigMap</span><span class=p>,</span> <span class=n>RBAC</span> <span class=n>Roles</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstraptoken</span><span class=p>]</span> <span class=n>configured</span> <span class=n>RBAC</span> <span class=n>rules</span> <span class=n>to</span> <span class=n>allow</span> <span class=ne>Node</span> <span class=n>Bootstrap</span> <span class=n>tokens</span> <span class=n>to</span> <span class=n>post</span> <span class=n>CSRs</span> <span class=ow>in</span> <span class=n>order</span> <span class=k>for</span> <span class=n>nodes</span> <span class=n>to</span> <span class=n>get</span> <span class=n>long</span> <span class=n>term</span> <span class=n>certificate</span> <span class=n>credentials</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstraptoken</span><span class=p>]</span> <span class=n>configured</span> <span class=n>RBAC</span> <span class=n>rules</span> <span class=n>to</span> <span class=n>allow</span> <span class=n>the</span> <span class=n>csrapprover</span> <span class=n>controller</span> <span class=n>automatically</span> <span class=n>approve</span> <span class=n>CSRs</span> <span class=n>from</span> <span class=n>a</span> <span class=ne>Node</span> <span class=n>Bootstrap</span> <span class=n>Token</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstraptoken</span><span class=p>]</span> <span class=n>configured</span> <span class=n>RBAC</span> <span class=n>rules</span> <span class=n>to</span> <span class=n>allow</span> <span class=n>certificate</span> <span class=n>rotation</span> <span class=k>for</span> <span class=n>all</span> <span class=n>node</span> <span class=n>client</span> <span class=n>certificates</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>cluster</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>bootstraptoken</span><span class=p>]</span> <span class=n>creating</span> <span class=n>the</span> <span class=s2>&#34;cluster-info&#34;</span> <span class=n>ConfigMap</span> <span class=ow>in</span> <span class=n>the</span> <span class=s2>&#34;kube-public&#34;</span> <span class=n>namespace</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>addons</span><span class=p>]</span> <span class=n>Applied</span> <span class=n>essential</span> <span class=n>addon</span><span class=p>:</span> <span class=n>CoreDNS</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>addons</span><span class=p>]</span> <span class=n>Applied</span> <span class=n>essential</span> <span class=n>addon</span><span class=p>:</span> <span class=n>kube</span><span class=o>-</span><span class=n>proxy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Your</span> <span class=n>Kubernetes</span> <span class=n>master</span> <span class=n>has</span> <span class=n>initialized</span> <span class=n>successfully</span><span class=o>!</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>To</span> <span class=n>start</span> <span class=n>using</span> <span class=n>your</span> <span class=n>cluster</span><span class=p>,</span> <span class=n>you</span> <span class=n>need</span> <span class=n>to</span> <span class=n>run</span> <span class=n>the</span> <span class=n>following</span> <span class=n>as</span> <span class=n>a</span> <span class=n>regular</span> <span class=n>user</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>mkdir</span> <span class=o>-</span><span class=n>p</span> <span class=o>$</span><span class=n>HOME</span><span class=o>/.</span><span class=n>kube</span>
</span></span><span class=line><span class=cl>  <span class=n>sudo</span> <span class=n>cp</span> <span class=o>-</span><span class=n>i</span> <span class=o>/</span><span class=n>etc</span><span class=o>/</span><span class=n>kubernetes</span><span class=o>/</span><span class=n>admin</span><span class=o>.</span><span class=n>conf</span> <span class=o>$</span><span class=n>HOME</span><span class=o>/.</span><span class=n>kube</span><span class=o>/</span><span class=n>config</span>
</span></span><span class=line><span class=cl>  <span class=n>sudo</span> <span class=n>chown</span> <span class=o>$</span><span class=p>(</span><span class=n>id</span> <span class=o>-</span><span class=n>u</span><span class=p>):</span><span class=o>$</span><span class=p>(</span><span class=n>id</span> <span class=o>-</span><span class=n>g</span><span class=p>)</span> <span class=o>$</span><span class=n>HOME</span><span class=o>/.</span><span class=n>kube</span><span class=o>/</span><span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>You</span> <span class=n>should</span> <span class=n>now</span> <span class=n>deploy</span> <span class=n>a</span> <span class=n>pod</span> <span class=n>network</span> <span class=n>to</span> <span class=n>the</span> <span class=n>cluster</span><span class=o>.</span>
</span></span><span class=line><span class=cl><span class=n>Run</span> <span class=s2>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> <span class=n>with</span> <span class=n>one</span> <span class=n>of</span> <span class=n>the</span> <span class=n>options</span> <span class=n>listed</span> <span class=n>at</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>kubernetes</span><span class=o>.</span><span class=n>io</span><span class=o>/</span><span class=n>docs</span><span class=o>/</span><span class=n>concepts</span><span class=o>/</span><span class=n>cluster</span><span class=o>-</span><span class=n>administration</span><span class=o>/</span><span class=n>addons</span><span class=o>/</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>You</span> <span class=n>can</span> <span class=n>now</span> <span class=n>join</span> <span class=n>any</span> <span class=n>number</span> <span class=n>of</span> <span class=n>machines</span> <span class=n>by</span> <span class=n>running</span> <span class=n>the</span> <span class=n>following</span> <span class=n>on</span> <span class=n>each</span> <span class=n>node</span>
</span></span><span class=line><span class=cl><span class=n>as</span> <span class=n>root</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>kubeadm</span> <span class=n>join</span> <span class=mf>192.168</span><span class=o>.</span><span class=mf>217.131</span><span class=p>:</span><span class=mi>6443</span> <span class=o>--</span><span class=n>token</span> <span class=mi>60</span><span class=n>syk6</span><span class=o>.</span><span class=n>vnplamkn3zhwu3s3</span> <span class=o>--</span><span class=n>discovery</span><span class=o>-</span><span class=n>token</span><span class=o>-</span><span class=n>ca</span><span class=o>-</span><span class=n>cert</span><span class=o>-</span><span class=nb>hash</span> <span class=n>sha256</span><span class=p>:</span><span class=mi>7</span><span class=n>d50e704bbfe69661e37c5f3ad13b1b88032b6b2b703ebd4899e259477b5be69</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>k8s</span><span class=o>-</span><span class=n>master</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></td></tr></table></div></div><p>(注意记录下初始化结果中的kubeadm join命令，部署worker节点时会用到)</p><p>初始化过程说明：</p><ol><li>[preflight] kubeadm 执行初始化前的检查。</li><li>[kubelet-start] 生成kubelet的配置文件”/var/lib/kubelet/config.yaml”</li><li>[certificates] 生成相关的各种token和证书</li><li>[kubeconfig] 生成 KubeConfig 文件，kubelet 需要这个文件与 Master 通信</li><li>[control-plane] 安装 Master 组件，会从指定的 Registry 下载组件的 Docker 镜像。</li><li>[bootstraptoken] 生成token记录下来，后边使用kubeadm join往集群中添加节点时会用到</li><li>[addons] 安装附加组件 kube-proxy 和 kube-dns。</li><li>Kubernetes Master 初始化成功，提示如何配置常规用户使用kubectl访问集群。</li><li>提示如何安装 Pod 网络。</li><li>提示如何注册其他节点到 Cluster。</li></ol><p><strong>配置 kubectl(master执行)</strong></p><p>kubectl 是管理 Kubernetes Cluster 的命令行工具，前面我们已经在所有的节点安装了 kubectl。Master 初始化完成后需要做一些配置工作，然后 kubectl 就能使用了。
依照 kubeadm init 输出的最后提示</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#追加sudo权限,并配置sudo免密
</span></span><span class=line><span class=cl>sed -i &#39;/^root/a\centos  ALL=(ALL)       NOPASSWD:ALL&#39; /etc/sudoers
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#保存集群安全配置文件到当前用户.kube目录
</span></span><span class=line><span class=cl>su - centos
</span></span><span class=line><span class=cl>mkdir -p $HOME/.kube
</span></span><span class=line><span class=cl>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span class=line><span class=cl>sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#启用 kubectl 命令自动补全功能（注销重新登录生效）
</span></span><span class=line><span class=cl>echo &#34;source &lt;(kubectl completion bash)&#34; &gt;&gt; ~/.bashrc
</span></span></code></pre></td></tr></table></div></div><p>需要这些配置命令的原因是：Kubernetes 集群默认需要加密方式访问。所以，这几条命令，就是将刚刚部署生成的 Kubernetes 集群的安全配置文件，保存到当前用户的.kube 目录下，kubectl 默认会使用这个目录下的授权信息访问 Kubernetes 集群。
如果不这么做的话，我们每次都需要通过 export KUBECONFIG 环境变量告诉 kubectl 这个安全配置文件的位置。
配置完成后centos用户就可以使用 kubectl 命令管理集群了。</p><p><strong>查看集群状态：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@k8s-master ~]$ kubectl get cs
</span></span><span class=line><span class=cl>NAME                 STATUS    MESSAGE              ERROR
</span></span><span class=line><span class=cl>scheduler            Healthy   ok
</span></span><span class=line><span class=cl>controller-manager   Healthy   ok
</span></span><span class=line><span class=cl>etcd-0               Healthy   {&#34;health&#34;: &#34;true&#34;}
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>确认各个组件都处于healthy状态。
<strong>查看节点状态</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@k8s-master ~]$ kubectl get nodes 
</span></span><span class=line><span class=cl>NAME         STATUS     ROLES    AGE   VERSION
</span></span><span class=line><span class=cl>k8s-master   NotReady   master   36m   v1.13.1
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>可以看到，当前只存在1个master节点，并且这个节点的状态是 NotReady。
使用 kubectl describe 命令来查看这个节点（Node）对象的详细信息、状态和事件（Event）：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@k8s-master ~]$ kubectl describe node k8s-master 
</span></span><span class=line><span class=cl>......
</span></span><span class=line><span class=cl>Events:
</span></span><span class=line><span class=cl>  Type    Reason                   Age                From                    Message
</span></span><span class=line><span class=cl>  ----    ------                   ----               ----                    -------
</span></span><span class=line><span class=cl>  Normal  Starting                 33m                kubelet, k8s-master     Starting kubelet.
</span></span><span class=line><span class=cl>  Normal  NodeHasSufficientMemory  33m (x8 over 33m)  kubelet, k8s-master     Node k8s-master status is now: NodeHasSufficientMemory
</span></span><span class=line><span class=cl>  Normal  NodeHasNoDiskPressure    33m (x8 over 33m)  kubelet, k8s-master     Node k8s-master status is now: NodeHasNoDiskPressure
</span></span><span class=line><span class=cl>  Normal  NodeHasSufficientPID     33m (x7 over 33m)  kubelet, k8s-master     Node k8s-master status is now: NodeHasSufficientPID
</span></span><span class=line><span class=cl>  Normal  NodeAllocatableEnforced  33m                kubelet, k8s-master     Updated Node Allocatable limit across pods
</span></span><span class=line><span class=cl>  Normal  Starting                 33m                kube-proxy, k8s-master  Starting kube-proxy.
</span></span></code></pre></td></tr></table></div></div><p>通过 kubectl describe 指令的输出，我们可以看到 NodeNotReady 的原因在于，我们尚未部署任何网络插件，kube-proxy等组件还处于starting状态。
另外，我们还可以通过 kubectl 检查这个节点上各个系统 Pod 的状态，其中，kube-system 是 Kubernetes 项目预留的系统 Pod 的工作空间（Namepsace，注意它并不是 Linux Namespace，它只是 Kubernetes 划分不同工作空间的单位）：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get pod -n kube-system -o wide
</span></span><span class=line><span class=cl>NAME                                 READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
</span></span><span class=line><span class=cl>coredns-78d4cf999f-7jdx7             0/1     Pending   0          29m   &lt;none&gt;          &lt;none&gt;       &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>coredns-78d4cf999f-s6mhk             0/1     Pending   0          29m   &lt;none&gt;          &lt;none&gt;       &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>etcd-k8s-master                      1/1     Running   0          34m   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-apiserver-k8s-master            1/1     Running   0          34m   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-controller-manager-k8s-master   1/1     Running   0          34m   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-proxy-przwf                     1/1     Running   0          34m   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-scheduler-k8s-master            1/1     Running   0          34m   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>可以看到，CoreDNS依赖于网络的 Pod 都处于 Pending 状态，即调度失败。这当然是符合预期的：因为这个 Master 节点的网络尚未就绪。
集群初始化如果遇到问题，可以使用kubeadm reset命令进行清理然后重新执行初始化。</p><p><strong>部署网络插件</strong>
要让 Kubernetes Cluster 能够工作，必须安装 Pod 网络，否则 Pod 之间无法通信。
Kubernetes 支持多种网络方案，这里我们使用 flannel
执行如下命令部署 flannel：
kubectl apply -f kube-flannel.yml</p><p>kube-flannel.yml文件</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span><span class=lnt>248
</span><span class=lnt>249
</span><span class=lnt>250
</span><span class=lnt>251
</span><span class=lnt>252
</span><span class=lnt>253
</span><span class=lnt>254
</span><span class=lnt>255
</span><span class=lnt>256
</span><span class=lnt>257
</span><span class=lnt>258
</span><span class=lnt>259
</span><span class=lnt>260
</span><span class=lnt>261
</span><span class=lnt>262
</span><span class=lnt>263
</span><span class=lnt>264
</span><span class=lnt>265
</span><span class=lnt>266
</span><span class=lnt>267
</span><span class=lnt>268
</span><span class=lnt>269
</span><span class=lnt>270
</span><span class=lnt>271
</span><span class=lnt>272
</span><span class=lnt>273
</span><span class=lnt>274
</span><span class=lnt>275
</span><span class=lnt>276
</span><span class=lnt>277
</span><span class=lnt>278
</span><span class=lnt>279
</span><span class=lnt>280
</span><span class=lnt>281
</span><span class=lnt>282
</span><span class=lnt>283
</span><span class=lnt>284
</span><span class=lnt>285
</span><span class=lnt>286
</span><span class=lnt>287
</span><span class=lnt>288
</span><span class=lnt>289
</span><span class=lnt>290
</span><span class=lnt>291
</span><span class=lnt>292
</span><span class=lnt>293
</span><span class=lnt>294
</span><span class=lnt>295
</span><span class=lnt>296
</span><span class=lnt>297
</span><span class=lnt>298
</span><span class=lnt>299
</span><span class=lnt>300
</span><span class=lnt>301
</span><span class=lnt>302
</span><span class=lnt>303
</span><span class=lnt>304
</span><span class=lnt>305
</span><span class=lnt>306
</span><span class=lnt>307
</span><span class=lnt>308
</span><span class=lnt>309
</span><span class=lnt>310
</span><span class=lnt>311
</span><span class=lnt>312
</span><span class=lnt>313
</span><span class=lnt>314
</span><span class=lnt>315
</span><span class=lnt>316
</span><span class=lnt>317
</span><span class=lnt>318
</span><span class=lnt>319
</span><span class=lnt>320
</span><span class=lnt>321
</span><span class=lnt>322
</span><span class=lnt>323
</span><span class=lnt>324
</span><span class=lnt>325
</span><span class=lnt>326
</span><span class=lnt>327
</span><span class=lnt>328
</span><span class=lnt>329
</span><span class=lnt>330
</span><span class=lnt>331
</span><span class=lnt>332
</span><span class=lnt>333
</span><span class=lnt>334
</span><span class=lnt>335
</span><span class=lnt>336
</span><span class=lnt>337
</span><span class=lnt>338
</span><span class=lnt>339
</span><span class=lnt>340
</span><span class=lnt>341
</span><span class=lnt>342
</span><span class=lnt>343
</span><span class=lnt>344
</span><span class=lnt>345
</span><span class=lnt>346
</span><span class=lnt>347
</span><span class=lnt>348
</span><span class=lnt>349
</span><span class=lnt>350
</span><span class=lnt>351
</span><span class=lnt>352
</span><span class=lnt>353
</span><span class=lnt>354
</span><span class=lnt>355
</span><span class=lnt>356
</span><span class=lnt>357
</span><span class=lnt>358
</span><span class=lnt>359
</span><span class=lnt>360
</span><span class=lnt>361
</span><span class=lnt>362
</span><span class=lnt>363
</span><span class=lnt>364
</span><span class=lnt>365
</span><span class=lnt>366
</span><span class=lnt>367
</span><span class=lnt>368
</span><span class=lnt>369
</span><span class=lnt>370
</span><span class=lnt>371
</span><span class=lnt>372
</span><span class=lnt>373
</span><span class=lnt>374
</span><span class=lnt>375
</span><span class=lnt>376
</span><span class=lnt>377
</span><span class=lnt>378
</span><span class=lnt>379
</span><span class=lnt>380
</span><span class=lnt>381
</span><span class=lnt>382
</span><span class=lnt>383
</span><span class=lnt>384
</span><span class=lnt>385
</span><span class=lnt>386
</span><span class=lnt>387
</span><span class=lnt>388
</span><span class=lnt>389
</span><span class=lnt>390
</span><span class=lnt>391
</span><span class=lnt>392
</span><span class=lnt>393
</span><span class=lnt>394
</span><span class=lnt>395
</span><span class=lnt>396
</span><span class=lnt>397
</span><span class=lnt>398
</span><span class=lnt>399
</span><span class=lnt>400
</span><span class=lnt>401
</span><span class=lnt>402
</span><span class=lnt>403
</span><span class=lnt>404
</span><span class=lnt>405
</span><span class=lnt>406
</span><span class=lnt>407
</span><span class=lnt>408
</span><span class=lnt>409
</span><span class=lnt>410
</span><span class=lnt>411
</span><span class=lnt>412
</span><span class=lnt>413
</span><span class=lnt>414
</span><span class=lnt>415
</span><span class=lnt>416
</span><span class=lnt>417
</span><span class=lnt>418
</span><span class=lnt>419
</span><span class=lnt>420
</span><span class=lnt>421
</span><span class=lnt>422
</span><span class=lnt>423
</span><span class=lnt>424
</span><span class=lnt>425
</span><span class=lnt>426
</span><span class=lnt>427
</span><span class=lnt>428
</span><span class=lnt>429
</span><span class=lnt>430
</span><span class=lnt>431
</span><span class=lnt>432
</span><span class=lnt>433
</span><span class=lnt>434
</span><span class=lnt>435
</span><span class=lnt>436
</span><span class=lnt>437
</span><span class=lnt>438
</span><span class=lnt>439
</span><span class=lnt>440
</span><span class=lnt>441
</span><span class=lnt>442
</span><span class=lnt>443
</span><span class=lnt>444
</span><span class=lnt>445
</span><span class=lnt>446
</span><span class=lnt>447
</span><span class=lnt>448
</span><span class=lnt>449
</span><span class=lnt>450
</span><span class=lnt>451
</span><span class=lnt>452
</span><span class=lnt>453
</span><span class=lnt>454
</span><span class=lnt>455
</span><span class=lnt>456
</span><span class=lnt>457
</span><span class=lnt>458
</span><span class=lnt>459
</span><span class=lnt>460
</span><span class=lnt>461
</span><span class=lnt>462
</span><span class=lnt>463
</span><span class=lnt>464
</span><span class=lnt>465
</span><span class=lnt>466
</span><span class=lnt>467
</span><span class=lnt>468
</span><span class=lnt>469
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kind: ClusterRole
</span></span><span class=line><span class=cl>apiVersion: rbac.authorization.k8s.io/v1beta1
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: flannel
</span></span><span class=line><span class=cl>rules:
</span></span><span class=line><span class=cl>  - apiGroups:
</span></span><span class=line><span class=cl>      - &#34;&#34;
</span></span><span class=line><span class=cl>    resources:
</span></span><span class=line><span class=cl>      - pods
</span></span><span class=line><span class=cl>    verbs:
</span></span><span class=line><span class=cl>      - get
</span></span><span class=line><span class=cl>  - apiGroups:
</span></span><span class=line><span class=cl>      - &#34;&#34;
</span></span><span class=line><span class=cl>    resources:
</span></span><span class=line><span class=cl>      - nodes
</span></span><span class=line><span class=cl>    verbs:
</span></span><span class=line><span class=cl>      - list
</span></span><span class=line><span class=cl>      - watch
</span></span><span class=line><span class=cl>  - apiGroups:
</span></span><span class=line><span class=cl>      - &#34;&#34;
</span></span><span class=line><span class=cl>    resources:
</span></span><span class=line><span class=cl>      - nodes/status
</span></span><span class=line><span class=cl>    verbs:
</span></span><span class=line><span class=cl>      - patch
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>kind: ClusterRoleBinding
</span></span><span class=line><span class=cl>apiVersion: rbac.authorization.k8s.io/v1beta1
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: flannel
</span></span><span class=line><span class=cl>roleRef:
</span></span><span class=line><span class=cl>  apiGroup: rbac.authorization.k8s.io
</span></span><span class=line><span class=cl>  kind: ClusterRole
</span></span><span class=line><span class=cl>  name: flannel
</span></span><span class=line><span class=cl>subjects:
</span></span><span class=line><span class=cl>- kind: ServiceAccount
</span></span><span class=line><span class=cl>  name: flannel
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: ServiceAccount
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: flannel
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>kind: ConfigMap
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: kube-flannel-cfg
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>  labels:
</span></span><span class=line><span class=cl>    tier: node
</span></span><span class=line><span class=cl>    app: flannel
</span></span><span class=line><span class=cl>data:
</span></span><span class=line><span class=cl>  cni-conf.json: |
</span></span><span class=line><span class=cl>    {
</span></span><span class=line><span class=cl>      &#34;name&#34;: &#34;cbr0&#34;,
</span></span><span class=line><span class=cl>      &#34;plugins&#34;: [
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>          &#34;type&#34;: &#34;flannel&#34;,
</span></span><span class=line><span class=cl>          &#34;delegate&#34;: {
</span></span><span class=line><span class=cl>            &#34;hairpinMode&#34;: true,
</span></span><span class=line><span class=cl>            &#34;isDefaultGateway&#34;: true
</span></span><span class=line><span class=cl>          }
</span></span><span class=line><span class=cl>        },
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>          &#34;type&#34;: &#34;portmap&#34;,
</span></span><span class=line><span class=cl>          &#34;capabilities&#34;: {
</span></span><span class=line><span class=cl>            &#34;portMappings&#34;: true
</span></span><span class=line><span class=cl>          }
</span></span><span class=line><span class=cl>        }
</span></span><span class=line><span class=cl>      ]
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>  net-conf.json: |
</span></span><span class=line><span class=cl>    {
</span></span><span class=line><span class=cl>      &#34;Network&#34;: &#34;10.244.0.0/16&#34;,
</span></span><span class=line><span class=cl>      &#34;Backend&#34;: {
</span></span><span class=line><span class=cl>        &#34;Type&#34;: &#34;vxlan&#34;
</span></span><span class=line><span class=cl>      }
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: extensions/v1beta1
</span></span><span class=line><span class=cl>kind: DaemonSet
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: kube-flannel-ds-amd64
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>  labels:
</span></span><span class=line><span class=cl>    tier: node
</span></span><span class=line><span class=cl>    app: flannel
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  template:
</span></span><span class=line><span class=cl>    metadata:
</span></span><span class=line><span class=cl>      labels:
</span></span><span class=line><span class=cl>        tier: node
</span></span><span class=line><span class=cl>        app: flannel
</span></span><span class=line><span class=cl>    spec:
</span></span><span class=line><span class=cl>      hostNetwork: true
</span></span><span class=line><span class=cl>      nodeSelector:
</span></span><span class=line><span class=cl>        beta.kubernetes.io/arch: amd64
</span></span><span class=line><span class=cl>      tolerations:
</span></span><span class=line><span class=cl>      - operator: Exists
</span></span><span class=line><span class=cl>        effect: NoSchedule
</span></span><span class=line><span class=cl>      serviceAccountName: flannel
</span></span><span class=line><span class=cl>      initContainers:
</span></span><span class=line><span class=cl>      - name: install-cni
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-amd64
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - cp
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - -f
</span></span><span class=line><span class=cl>        - /etc/kube-flannel/cni-conf.json
</span></span><span class=line><span class=cl>        - /etc/cni/net.d/10-flannel.conflist
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          mountPath: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      containers:
</span></span><span class=line><span class=cl>      - name: kube-flannel
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-amd64
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - /opt/bin/flanneld
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - --ip-masq
</span></span><span class=line><span class=cl>        - --kube-subnet-mgr
</span></span><span class=line><span class=cl>        resources:
</span></span><span class=line><span class=cl>          requests:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>          limits:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>        securityContext:
</span></span><span class=line><span class=cl>          privileged: true
</span></span><span class=line><span class=cl>        env:
</span></span><span class=line><span class=cl>        - name: POD_NAME
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.name
</span></span><span class=line><span class=cl>        - name: POD_NAMESPACE
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.namespace
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          mountPath: /run
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      volumes:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /run
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          configMap:
</span></span><span class=line><span class=cl>            name: kube-flannel-cfg
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: extensions/v1beta1
</span></span><span class=line><span class=cl>kind: DaemonSet
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: kube-flannel-ds-arm64
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>  labels:
</span></span><span class=line><span class=cl>    tier: node
</span></span><span class=line><span class=cl>    app: flannel
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  template:
</span></span><span class=line><span class=cl>    metadata:
</span></span><span class=line><span class=cl>      labels:
</span></span><span class=line><span class=cl>        tier: node
</span></span><span class=line><span class=cl>        app: flannel
</span></span><span class=line><span class=cl>    spec:
</span></span><span class=line><span class=cl>      hostNetwork: true
</span></span><span class=line><span class=cl>      nodeSelector:
</span></span><span class=line><span class=cl>        beta.kubernetes.io/arch: arm64
</span></span><span class=line><span class=cl>      tolerations:
</span></span><span class=line><span class=cl>      - operator: Exists
</span></span><span class=line><span class=cl>        effect: NoSchedule
</span></span><span class=line><span class=cl>      serviceAccountName: flannel
</span></span><span class=line><span class=cl>      initContainers:
</span></span><span class=line><span class=cl>      - name: install-cni
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-arm64
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - cp
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - -f
</span></span><span class=line><span class=cl>        - /etc/kube-flannel/cni-conf.json
</span></span><span class=line><span class=cl>        - /etc/cni/net.d/10-flannel.conflist
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          mountPath: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      containers:
</span></span><span class=line><span class=cl>      - name: kube-flannel
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-arm64
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - /opt/bin/flanneld
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - --ip-masq
</span></span><span class=line><span class=cl>        - --kube-subnet-mgr
</span></span><span class=line><span class=cl>        resources:
</span></span><span class=line><span class=cl>          requests:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>          limits:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>        securityContext:
</span></span><span class=line><span class=cl>          privileged: true
</span></span><span class=line><span class=cl>        env:
</span></span><span class=line><span class=cl>        - name: POD_NAME
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.name
</span></span><span class=line><span class=cl>        - name: POD_NAMESPACE
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.namespace
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          mountPath: /run
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      volumes:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /run
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          configMap:
</span></span><span class=line><span class=cl>            name: kube-flannel-cfg
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: extensions/v1beta1
</span></span><span class=line><span class=cl>kind: DaemonSet
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: kube-flannel-ds-arm
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>  labels:
</span></span><span class=line><span class=cl>    tier: node
</span></span><span class=line><span class=cl>    app: flannel
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  template:
</span></span><span class=line><span class=cl>    metadata:
</span></span><span class=line><span class=cl>      labels:
</span></span><span class=line><span class=cl>        tier: node
</span></span><span class=line><span class=cl>        app: flannel
</span></span><span class=line><span class=cl>    spec:
</span></span><span class=line><span class=cl>      hostNetwork: true
</span></span><span class=line><span class=cl>      nodeSelector:
</span></span><span class=line><span class=cl>        beta.kubernetes.io/arch: arm
</span></span><span class=line><span class=cl>      tolerations:
</span></span><span class=line><span class=cl>      - operator: Exists
</span></span><span class=line><span class=cl>        effect: NoSchedule
</span></span><span class=line><span class=cl>      serviceAccountName: flannel
</span></span><span class=line><span class=cl>      initContainers:
</span></span><span class=line><span class=cl>      - name: install-cni
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-arm
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - cp
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - -f
</span></span><span class=line><span class=cl>        - /etc/kube-flannel/cni-conf.json
</span></span><span class=line><span class=cl>        - /etc/cni/net.d/10-flannel.conflist
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          mountPath: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      containers:
</span></span><span class=line><span class=cl>      - name: kube-flannel
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-arm
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - /opt/bin/flanneld
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - --ip-masq
</span></span><span class=line><span class=cl>        - --kube-subnet-mgr
</span></span><span class=line><span class=cl>        resources:
</span></span><span class=line><span class=cl>          requests:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>          limits:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>        securityContext:
</span></span><span class=line><span class=cl>          privileged: true
</span></span><span class=line><span class=cl>        env:
</span></span><span class=line><span class=cl>        - name: POD_NAME
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.name
</span></span><span class=line><span class=cl>        - name: POD_NAMESPACE
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.namespace
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          mountPath: /run
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      volumes:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /run
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          configMap:
</span></span><span class=line><span class=cl>            name: kube-flannel-cfg
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: extensions/v1beta1
</span></span><span class=line><span class=cl>kind: DaemonSet
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: kube-flannel-ds-ppc64le
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>  labels:
</span></span><span class=line><span class=cl>    tier: node
</span></span><span class=line><span class=cl>    app: flannel
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  template:
</span></span><span class=line><span class=cl>    metadata:
</span></span><span class=line><span class=cl>      labels:
</span></span><span class=line><span class=cl>        tier: node
</span></span><span class=line><span class=cl>        app: flannel
</span></span><span class=line><span class=cl>    spec:
</span></span><span class=line><span class=cl>      hostNetwork: true
</span></span><span class=line><span class=cl>      nodeSelector:
</span></span><span class=line><span class=cl>        beta.kubernetes.io/arch: ppc64le
</span></span><span class=line><span class=cl>      tolerations:
</span></span><span class=line><span class=cl>      - operator: Exists
</span></span><span class=line><span class=cl>        effect: NoSchedule
</span></span><span class=line><span class=cl>      serviceAccountName: flannel
</span></span><span class=line><span class=cl>      initContainers:
</span></span><span class=line><span class=cl>      - name: install-cni
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-ppc64le
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - cp
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - -f
</span></span><span class=line><span class=cl>        - /etc/kube-flannel/cni-conf.json
</span></span><span class=line><span class=cl>        - /etc/cni/net.d/10-flannel.conflist
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          mountPath: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      containers:
</span></span><span class=line><span class=cl>      - name: kube-flannel
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-ppc64le
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - /opt/bin/flanneld
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - --ip-masq
</span></span><span class=line><span class=cl>        - --kube-subnet-mgr
</span></span><span class=line><span class=cl>        resources:
</span></span><span class=line><span class=cl>          requests:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>          limits:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>        securityContext:
</span></span><span class=line><span class=cl>          privileged: true
</span></span><span class=line><span class=cl>        env:
</span></span><span class=line><span class=cl>        - name: POD_NAME
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.name
</span></span><span class=line><span class=cl>        - name: POD_NAMESPACE
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.namespace
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          mountPath: /run
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      volumes:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /run
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          configMap:
</span></span><span class=line><span class=cl>            name: kube-flannel-cfg
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: extensions/v1beta1
</span></span><span class=line><span class=cl>kind: DaemonSet
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: kube-flannel-ds-s390x
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>  labels:
</span></span><span class=line><span class=cl>    tier: node
</span></span><span class=line><span class=cl>    app: flannel
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  template:
</span></span><span class=line><span class=cl>    metadata:
</span></span><span class=line><span class=cl>      labels:
</span></span><span class=line><span class=cl>        tier: node
</span></span><span class=line><span class=cl>        app: flannel
</span></span><span class=line><span class=cl>    spec:
</span></span><span class=line><span class=cl>      hostNetwork: true
</span></span><span class=line><span class=cl>      nodeSelector:
</span></span><span class=line><span class=cl>        beta.kubernetes.io/arch: s390x
</span></span><span class=line><span class=cl>      tolerations:
</span></span><span class=line><span class=cl>      - operator: Exists
</span></span><span class=line><span class=cl>        effect: NoSchedule
</span></span><span class=line><span class=cl>      serviceAccountName: flannel
</span></span><span class=line><span class=cl>      initContainers:
</span></span><span class=line><span class=cl>      - name: install-cni
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-s390x
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - cp
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - -f
</span></span><span class=line><span class=cl>        - /etc/kube-flannel/cni-conf.json
</span></span><span class=line><span class=cl>        - /etc/cni/net.d/10-flannel.conflist
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          mountPath: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      containers:
</span></span><span class=line><span class=cl>      - name: kube-flannel
</span></span><span class=line><span class=cl>        image: quay.io/coreos/flannel:v0.10.0-s390x
</span></span><span class=line><span class=cl>        command:
</span></span><span class=line><span class=cl>        - /opt/bin/flanneld
</span></span><span class=line><span class=cl>        args:
</span></span><span class=line><span class=cl>        - --ip-masq
</span></span><span class=line><span class=cl>        - --kube-subnet-mgr
</span></span><span class=line><span class=cl>        resources:
</span></span><span class=line><span class=cl>          requests:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>          limits:
</span></span><span class=line><span class=cl>            cpu: &#34;100m&#34;
</span></span><span class=line><span class=cl>            memory: &#34;50Mi&#34;
</span></span><span class=line><span class=cl>        securityContext:
</span></span><span class=line><span class=cl>          privileged: true
</span></span><span class=line><span class=cl>        env:
</span></span><span class=line><span class=cl>        - name: POD_NAME
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.name
</span></span><span class=line><span class=cl>        - name: POD_NAMESPACE
</span></span><span class=line><span class=cl>          valueFrom:
</span></span><span class=line><span class=cl>            fieldRef:
</span></span><span class=line><span class=cl>              fieldPath: metadata.namespace
</span></span><span class=line><span class=cl>        volumeMounts:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          mountPath: /run
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          mountPath: /etc/kube-flannel/
</span></span><span class=line><span class=cl>      volumes:
</span></span><span class=line><span class=cl>        - name: run
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /run
</span></span><span class=line><span class=cl>        - name: cni
</span></span><span class=line><span class=cl>          hostPath:
</span></span><span class=line><span class=cl>            path: /etc/cni/net.d
</span></span><span class=line><span class=cl>        - name: flannel-cfg
</span></span><span class=line><span class=cl>          configMap:
</span></span><span class=line><span class=cl>            name: kube-flannel-cfg
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl apply -f kube-flannel.yml
</span></span><span class=line><span class=cl>clusterrole.rbac.authorization.k8s.io/flannel created
</span></span><span class=line><span class=cl>clusterrolebinding.rbac.authorization.k8s.io/flannel created
</span></span><span class=line><span class=cl>serviceaccount/flannel created
</span></span><span class=line><span class=cl>configmap/kube-flannel-cfg created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-amd64 created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-arm64 created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-arm created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-ppc64le created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-s390x created
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>部署完成后，我们可以通过 kubectl get 重新检查 Pod 的状态（如果没running状态可以再次应用或者等待一段时间）：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get pod -n kube-system -o wide
</span></span><span class=line><span class=cl>NAME                                 READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
</span></span><span class=line><span class=cl>coredns-78d4cf999f-7jdx7             1/1     Running   0          11h   10.244.0.3      k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>coredns-78d4cf999f-s6mhk             1/1     Running   0          11h   10.244.0.2      k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>etcd-k8s-master                      1/1     Running   1          11h   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-apiserver-k8s-master            1/1     Running   1          11h   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-controller-manager-k8s-master   1/1     Running   1          11h   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-flannel-ds-amd64-lkf2f          1/1     Running   0          10h   192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-proxy-przwf                     1/1     Running   1          11h   192.168.217.131  k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-scheduler-k8s-master            1/1     Running   1          11h   192.168.217.131  k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>可以看到，所有的系统 Pod 都成功启动了，而刚刚部署的flannel网络插件则在 kube-system 下面新建了一个名叫kube-flannel-ds-amd64-lkf2f的 Pod，一般来说，这些 Pod 就是容器网络插件在每个节点上的控制组件。
Kubernetes 支持容器网络插件，使用的是一个名叫 CNI 的通用接口，它也是当前容器网络的事实标准，市面上的所有容器网络开源项目都可以通过 CNI 接入 Kubernetes，比如 Flannel、Calico、Canal、Romana 等等，它们的部署方式也都是类似的“一键部署”。
再次查看master节点状态已经为ready状态：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get nodes 
</span></span><span class=line><span class=cl>NAME         STATUS   ROLES    AGE   VERSION
</span></span><span class=line><span class=cl>k8s-master   Ready    master   11h   v1.13.1
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>至此，Kubernetes 的 Master 节点就部署完成了。如果你只需要一个单节点的 Kubernetes，现在你就可以使用了。不过，在默认情况下，Kubernetes 的 Master 节点是不能运行用户 Pod 的。</p><h2 id=3部署workernode节点>3.部署worker(node)节点</h2><p>Kubernetes 的 Worker 节点跟 Master 节点几乎是相同的，它们运行着的都是一个 kubelet 组件。唯一的区别在于，在 kubeadm init 的过程中，kubelet 启动后，Master 节点上还会自动运行 kube-apiserver、kube-scheduler、kube-controller-manger 这三个系统 Pod。
在 k8s-node1 和 k8s-node2 上分别执行如下命令，将其注册到 Cluster 中：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#执行以下命令将节点接入集群
</span></span><span class=line><span class=cl>kubeadm join 192.168.217.131:6443 --token 67kq55.8hxoga556caxty7s --discovery-token-ca-cert-hash sha256:7d50e704bbfe69661e37c5f3ad13b1b88032b6b2b703ebd4899e259477b5be69
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#如果执行kubeadm init时没有记录下加入集群的命令，可以通过以下命令重新创建
</span></span><span class=line><span class=cl>kubeadm token create --print-join-command
</span></span></code></pre></td></tr></table></div></div><p>在k8s-node1上执行kubeadm join ：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>k8s</span><span class=o>-</span><span class=n>node1</span> <span class=o>~</span><span class=p>]</span><span class=c1># kubeadm join 192.168.217.131:6443 --token 67kq55.8hxoga556caxty7s --discovery-token-ca-cert-hash sha256:7d50e704bbfe69661e37c5f3ad13b1b88032b6b2b703ebd4899e259477b5be69</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>preflight</span><span class=p>]</span> <span class=n>Running</span> <span class=n>pre</span><span class=o>-</span><span class=n>flight</span> <span class=n>checks</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>discovery</span><span class=p>]</span> <span class=n>Trying</span> <span class=n>to</span> <span class=n>connect</span> <span class=n>to</span> <span class=n>API</span> <span class=n>Server</span> <span class=s2>&#34;192.168.217.131:6443&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>discovery</span><span class=p>]</span> <span class=n>Created</span> <span class=n>cluster</span><span class=o>-</span><span class=n>info</span> <span class=n>discovery</span> <span class=n>client</span><span class=p>,</span> <span class=n>requesting</span> <span class=n>info</span> <span class=n>from</span> <span class=s2>&#34;https://192.168.217.131:6443&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>discovery</span><span class=p>]</span> <span class=n>Requesting</span> <span class=n>info</span> <span class=n>from</span> <span class=s2>&#34;https://192.168.217.131:6443&#34;</span> <span class=n>again</span> <span class=n>to</span> <span class=n>validate</span> <span class=n>TLS</span> <span class=n>against</span> <span class=n>the</span> <span class=n>pinned</span> <span class=n>public</span> <span class=n>key</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>discovery</span><span class=p>]</span> <span class=n>Cluster</span> <span class=n>info</span> <span class=n>signature</span> <span class=ow>and</span> <span class=n>contents</span> <span class=n>are</span> <span class=n>valid</span> <span class=ow>and</span> <span class=n>TLS</span> <span class=n>certificate</span> <span class=n>validates</span> <span class=n>against</span> <span class=n>pinned</span> <span class=n>roots</span><span class=p>,</span> <span class=n>will</span> <span class=n>use</span> <span class=n>API</span> <span class=n>Server</span> <span class=s2>&#34;192.168.217.131:6443&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>discovery</span><span class=p>]</span> <span class=n>Successfully</span> <span class=n>established</span> <span class=n>connection</span> <span class=n>with</span> <span class=n>API</span> <span class=n>Server</span> <span class=s2>&#34;192.168.217.131:6443&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>join</span><span class=p>]</span> <span class=n>Reading</span> <span class=n>configuration</span> <span class=n>from</span> <span class=n>the</span> <span class=n>cluster</span><span class=o>...</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>join</span><span class=p>]</span> <span class=n>FYI</span><span class=p>:</span> <span class=n>You</span> <span class=n>can</span> <span class=n>look</span> <span class=n>at</span> <span class=n>this</span> <span class=n>config</span> <span class=n>file</span> <span class=n>with</span> <span class=s1>&#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=p>]</span> <span class=n>Downloading</span> <span class=n>configuration</span> <span class=k>for</span> <span class=n>the</span> <span class=n>kubelet</span> <span class=n>from</span> <span class=n>the</span> <span class=s2>&#34;kubelet-config-1.13&#34;</span> <span class=n>ConfigMap</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>kube</span><span class=o>-</span><span class=n>system</span> <span class=n>namespace</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Writing</span> <span class=n>kubelet</span> <span class=n>configuration</span> <span class=n>to</span> <span class=n>file</span> <span class=s2>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Writing</span> <span class=n>kubelet</span> <span class=n>environment</span> <span class=n>file</span> <span class=n>with</span> <span class=n>flags</span> <span class=n>to</span> <span class=n>file</span> <span class=s2>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>kubelet</span><span class=o>-</span><span class=n>start</span><span class=p>]</span> <span class=n>Activating</span> <span class=n>the</span> <span class=n>kubelet</span> <span class=n>service</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>tlsbootstrap</span><span class=p>]</span> <span class=n>Waiting</span> <span class=k>for</span> <span class=n>the</span> <span class=n>kubelet</span> <span class=n>to</span> <span class=n>perform</span> <span class=n>the</span> <span class=n>TLS</span> <span class=n>Bootstrap</span><span class=o>...</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>patchnode</span><span class=p>]</span> <span class=n>Uploading</span> <span class=n>the</span> <span class=n>CRI</span> <span class=n>Socket</span> <span class=n>information</span> <span class=s2>&#34;/var/run/dockershim.sock&#34;</span> <span class=n>to</span> <span class=n>the</span> <span class=ne>Node</span> <span class=n>API</span> <span class=n>object</span> <span class=s2>&#34;k8s-node1&#34;</span> <span class=n>as</span> <span class=n>an</span> <span class=n>annotation</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>This</span> <span class=n>node</span> <span class=n>has</span> <span class=n>joined</span> <span class=n>the</span> <span class=n>cluster</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=o>*</span> <span class=n>Certificate</span> <span class=n>signing</span> <span class=n>request</span> <span class=n>was</span> <span class=n>sent</span> <span class=n>to</span> <span class=n>apiserver</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>response</span> <span class=n>was</span> <span class=n>received</span><span class=o>.</span>
</span></span><span class=line><span class=cl><span class=o>*</span> <span class=n>The</span> <span class=n>Kubelet</span> <span class=n>was</span> <span class=n>informed</span> <span class=n>of</span> <span class=n>the</span> <span class=n>new</span> <span class=n>secure</span> <span class=n>connection</span> <span class=n>details</span><span class=o>.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Run</span> <span class=s1>&#39;kubectl get nodes&#39;</span> <span class=n>on</span> <span class=n>the</span> <span class=n>master</span> <span class=n>to</span> <span class=n>see</span> <span class=n>this</span> <span class=n>node</span> <span class=n>join</span> <span class=n>the</span> <span class=n>cluster</span><span class=o>.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>root</span><span class=err>@</span><span class=n>k8s</span><span class=o>-</span><span class=n>node1</span> <span class=o>~</span><span class=p>]</span><span class=c1>#</span>
</span></span></code></pre></td></tr></table></div></div><p>重复执行以上操作将k8s-node2也加进去（注意重新执行kubeadm token create –print-join-command）。
然后根据提示，我们可以通过 kubectl get nodes 查看节点的状态：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get nodes
</span></span><span class=line><span class=cl>NAME         STATUS   ROLES    AGE    VERSION
</span></span><span class=line><span class=cl>k8s-master   Ready    master   11h    v1.13.1
</span></span><span class=line><span class=cl>k8s-node1    Ready    &lt;none&gt;   24m    v1.13.1
</span></span><span class=line><span class=cl>k8s-node2    Ready    &lt;none&gt;   4m9s   v1.13.1
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>nodes状态全部为ready，由于每个节点都需要启动若干组件，如果node节点的状态是 NotReady，可以查看所有节点pod状态，确保所有pod成功拉取到镜像并处于running状态：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get pod --all-namespaces -o wide
</span></span><span class=line><span class=cl>NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES
</span></span><span class=line><span class=cl>kube-system   coredns-78d4cf999f-7jdx7             1/1     Running   0          11h     10.244.0.3      k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   coredns-78d4cf999f-s6mhk             1/1     Running   0          11h     10.244.0.2      k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   etcd-k8s-master                      1/1     Running   1          12h     192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-apiserver-k8s-master            1/1     Running   1          12h     192.168.217.131  k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-controller-manager-k8s-master   1/1     Running   1          12h     192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-flannel-ds-amd64-d2r8p          1/1     Running   0          6m43s   192.168.58.102   k8s-node2    &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-flannel-ds-amd64-d85c6          1/1     Running   0          27m     192.168.58.101   k8s-node1    &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-flannel-ds-amd64-lkf2f          1/1     Running   0          11h     192.168.217.131  k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-proxy-k8jx8                     1/1     Running   0          6m43s   192.168.58.102   k8s-node2    &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-proxy-n95ck                     1/1     Running   0          27m     192.168.58.101  k8s-node1    &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-proxy-przwf                     1/1     Running   1          12h     192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-system   kube-scheduler-k8s-master            1/1     Running   1          12h     192.168.217.131   k8s-master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>这时，所有的节点都已经 Ready，Kubernetes Cluster 创建成功，一切准备就绪。
如果pod状态为Pending、ContainerCreating、ImagePullBackOff 都表明 Pod 没有就绪，Running 才是就绪状态。
如果有pod提示Init:ImagePullBackOff，说明这个pod的镜像在对应节点上拉取失败，我们可以通过 kubectl describe pod 查看 Pod 具体情况，以确认拉取失败的镜像：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl describe pod kube-flannel-ds-amd64-d2r8p --namespace=kube-system
</span></span><span class=line><span class=cl>......
</span></span><span class=line><span class=cl>Events:
</span></span><span class=line><span class=cl>  Type     Reason     Age                 From                Message
</span></span><span class=line><span class=cl>  ----     ------     ----                ----                -------
</span></span><span class=line><span class=cl>  Normal   Scheduled  2m14s               default-scheduler   Successfully assigned kube-system/kube-flannel-ds-amd64-lzx5v to k8s-node2
</span></span><span class=line><span class=cl>  Warning  Failed     109s                kubelet, k8s-node2  Failed to pull image &#34;quay.io/coreos/flannel:v0.10.0-amd64&#34;: rpc error: code = Unknown desc = Error response from daemon: Get https://quay.io/v2/: net/http: TLS handshake timeout
</span></span><span class=line><span class=cl>  Warning  Failed     109s                kubelet, k8s-node2  Error: ErrImagePull
</span></span><span class=line><span class=cl>  Normal   BackOff    108s                kubelet, k8s-node2  Back-off pulling image &#34;quay.io/coreos/flannel:v0.10.0-amd64&#34;
</span></span><span class=line><span class=cl>  Warning  Failed     108s                kubelet, k8s-node2  Error: ImagePullBackOff
</span></span><span class=line><span class=cl>  Normal   Pulling    94s (x2 over 2m6s)  kubelet, k8s-node2  pulling image &#34;quay.io/coreos/flannel:v0.10.0-amd64&#34;
</span></span></code></pre></td></tr></table></div></div><p>这里看最后events输出内容，可以看到在下载 image 时失败，如果网络质量不好，这种情况是很常见的。我们可以耐心等待，因为 Kubernetes 会重试，我们也可以自己手工执行 docker pull 去下载这个镜像。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@k8s-node2 ~]# docker pull quay.io/coreos/flannel:v0.10.0-amd64
</span></span><span class=line><span class=cl>v0.10.0-amd64: Pulling from coreos/flannel
</span></span><span class=line><span class=cl>ff3a5c916c92: Already exists
</span></span><span class=line><span class=cl>8a8433d1d437: Already exists
</span></span><span class=line><span class=cl>306dc0ee491a: Already exists
</span></span><span class=line><span class=cl>856cbd0b7b9c: Already exists
</span></span><span class=line><span class=cl>af6d1e4decc6: Already exists
</span></span><span class=line><span class=cl>Digest: sha256:88f2b4d96fae34bfff3d46293f7f18d1f9f3ca026b4a4d288f28347fcb6580ac
</span></span><span class=line><span class=cl>Status: Image is up to date for quay.io/coreos/flannel:v0.10.0-amd64
</span></span><span class=line><span class=cl>[root@k8s-node2 ~]#
</span></span></code></pre></td></tr></table></div></div><p>如果无法从 quay.io/coreos/flannel:v0.10.0-amd64 下载镜像，可以从阿里云或者dockerhub镜像仓库下载，然后改回原来的tag即可：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>docker pull registry.cn-hangzhou.aliyuncs.com/kubernetes_containers/flannel:v0.10.0-amd64
</span></span><span class=line><span class=cl>docker tag registry.cn-hangzhou.aliyuncs.com/kubernetes_containers/flannel:v0.10.0-amd64 quay.io/coreos/flannel:v0.10.0-amd64
</span></span><span class=line><span class=cl>docker rmi registry.cn-hangzhou.aliyuncs.com/kubernetes_containers/flannel:v0.10.0-amd64
</span></span></code></pre></td></tr></table></div></div><p>查看master节点下载了哪些镜像：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ sudo docker images
</span></span><span class=line><span class=cl>REPOSITORY                                                        TAG                 IMAGE ID            CREATED             SIZE
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/kube-proxy                v1.13.1             fdb321fd30a0        2 weeks ago         80.2MB
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/kube-apiserver            v1.13.1             40a63db91ef8        2 weeks ago         181MB
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/kube-scheduler            v1.13.1             ab81d7360408        2 weeks ago         79.6MB
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/kube-controller-manager   v1.13.1             26e6f1db2a52        2 weeks ago         146MB
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/coredns                   1.2.6               f59dcacceff4        8 weeks ago         40MB
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/etcd                      3.2.24              3cab8e1b9802        3 months ago        220MB
</span></span><span class=line><span class=cl>quay.io/coreos/flannel                                            v0.10.0-amd64       f0fad859c909        11 months ago       44.6MB
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/pause                     3.1                 da86e6ba6ca1        12 months ago       742kB
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>查看node节点下载了哪些镜像：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@k8s-node1 ~]# docker images
</span></span><span class=line><span class=cl>REPOSITORY                                           TAG                 IMAGE ID            CREATED             SIZE
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/kube-proxy   v1.13.1             fdb321fd30a0        2 weeks ago         80.2MB
</span></span><span class=line><span class=cl>quay.io/coreos/flannel                               v0.10.0-amd64       f0fad859c909        11 months ago       44.6MB
</span></span><span class=line><span class=cl>registry.aliyuncs.com/google_containers/pause        3.1                 da86e6ba6ca1        12 months ago       742kB
</span></span><span class=line><span class=cl>[root@k8s-node1 ~]#
</span></span></code></pre></td></tr></table></div></div><h2 id=测试集群各个组件>测试集群各个组件</h2><p><strong>首先验证kube-apiserver, kube-controller-manager, kube-scheduler, pod network 是否正常：</strong>
部署一个 Nginx Deployment，包含2个Pod
参考：<a href=https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ target=_blank rel="noopener noreffer">https://kubernetes.io/docs/concepts/workloads/controllers/deployment/</a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl create deployment nginx --image=nginx:alpine
</span></span><span class=line><span class=cl>deployment.apps/nginx created
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl scale deployment nginx --replicas=2
</span></span><span class=line><span class=cl>deployment.extensions/nginx scaled
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>验证Nginx Pod是否正确运行，并且会分配10.244.开头的集群IP</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get pods -l app=nginx -o wide
</span></span><span class=line><span class=cl>NAME                     READY   STATUS    RESTARTS   AGE    IP           NODE        NOMINATED NODE   READINESS GATES
</span></span><span class=line><span class=cl>nginx-54458cd494-p2qgx   1/1     Running   0          111s   10.244.1.2   k8s-node1   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>nginx-54458cd494-sdlm7   1/1     Running   0          103s   10.244.2.2   k8s-node2   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p><strong>再验证一下kube-proxy是否正常：</strong></p><p>以 NodePort 方式对外提供服务
参考：<a href=https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/ target=_blank rel="noopener noreffer">https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/</a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl expose deployment nginx --port=80 --type=NodePort
</span></span><span class=line><span class=cl>service/nginx exposed
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get services nginx
</span></span><span class=line><span class=cl>NAME    TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE
</span></span><span class=line><span class=cl>nginx   NodePort   10.108.17.2   &lt;none&gt;        80:30670/TCP   12s
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>可以通过任意 NodeIP:Port 在集群外部访问这个服务：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ curl 192.168.217.131:30670
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$ curl 192.168.58.102:30670
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$ curl 192.168.58.101:30670
</span></span></code></pre></td></tr></table></div></div><p>访问k8s-master ip</p><p>访问k8s-node1 ip</p><p>访问k8s-node2 ip</p><p><strong>最后验证一下dns, pod network是否正常：</strong>
运行Busybox并进入交互模式</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl run -it curl --image=radial/busyboxplus:curl
</span></span><span class=line><span class=cl>kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
</span></span><span class=line><span class=cl>If you don&#39;t see a command prompt, try pressing enter.
</span></span><span class=line><span class=cl>[ root@curl-66959f6557-s5qqs:/ ]$
</span></span></code></pre></td></tr></table></div></div><p>输入<code>nslookup nginx</code>查看是否可以正确解析出集群内的IP，以验证DNS是否正常</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[ root@curl-66959f6557-s5qqs:/ ]$ nslookup nginx
</span></span><span class=line><span class=cl>Server:    10.96.0.10
</span></span><span class=line><span class=cl>Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Name:      nginx
</span></span><span class=line><span class=cl>Address 1: 10.108.17.2 nginx.default.svc.cluster.local
</span></span></code></pre></td></tr></table></div></div><p>通过服务名进行访问，验证kube-proxy是否正常</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[ root@curl-66959f6557-q472z:/ ]$ curl http://nginx/
</span></span><span class=line><span class=cl>&lt;!DOCTYPE html&gt;
</span></span><span class=line><span class=cl>&lt;html&gt;
</span></span><span class=line><span class=cl>&lt;head&gt;
</span></span><span class=line><span class=cl>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span><span class=line><span class=cl>......
</span></span><span class=line><span class=cl>&lt;/body&gt;
</span></span><span class=line><span class=cl>&lt;/html&gt;
</span></span><span class=line><span class=cl>[ root@curl-66959f6557-q472z:/ ]$
</span></span></code></pre></td></tr></table></div></div><p>分别访问一下2个Pod的内网IP，验证跨Node的网络通信是否正常</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[ root@curl-66959f6557-s5qqs:/ ]$ curl 10.244.1.2
</span></span><span class=line><span class=cl>&lt;!DOCTYPE html&gt;
</span></span><span class=line><span class=cl>&lt;html&gt;
</span></span><span class=line><span class=cl>&lt;head&gt;
</span></span><span class=line><span class=cl>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span><span class=line><span class=cl>......
</span></span><span class=line><span class=cl>&lt;/body&gt;
</span></span><span class=line><span class=cl>&lt;/html&gt;
</span></span><span class=line><span class=cl>[ root@curl-66959f6557-s5qqs:/ ]$ curl 10.244.2.2
</span></span><span class=line><span class=cl>&lt;!DOCTYPE html&gt;
</span></span><span class=line><span class=cl>&lt;html&gt;
</span></span><span class=line><span class=cl>&lt;head&gt;
</span></span><span class=line><span class=cl>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span><span class=line><span class=cl>......
</span></span><span class=line><span class=cl>&lt;/body&gt;
</span></span><span class=line><span class=cl>&lt;/html&gt;
</span></span><span class=line><span class=cl>[ root@curl-66959f6557-s5qqs:/ ]$
</span></span></code></pre></td></tr></table></div></div><h2 id=pod调度到master节点可以不做>Pod调度到Master节点（可以不做）</h2><p>出于安全考虑，默认配置下Kubernetes不会将Pod调度到Master节点。查看Taints字段默认配置：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl describe node k8s-master 
</span></span><span class=line><span class=cl>......
</span></span><span class=line><span class=cl>Taints:             node-role.kubernetes.io/master:NoSchedule
</span></span></code></pre></td></tr></table></div></div><p>如果希望将k8s-master也当作Node节点使用，可以执行如下命令,其中k8s-master是主机节点hostname：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl taint node k8s-master node-role.kubernetes.io/master-
</span></span></code></pre></td></tr></table></div></div><p>修改后Taints字段状态：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl describe node k8s-master                             
</span></span><span class=line><span class=cl>......
</span></span><span class=line><span class=cl>Taints:             &lt;none&gt;
</span></span></code></pre></td></tr></table></div></div><p>如果要恢复Master Only状态，执行如下命令：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl taint node k8s-master node-role.kubernetes.io/master=&#34;&#34;
</span></span></code></pre></td></tr></table></div></div><h2 id=kube-proxy开启ipvs>kube-proxy开启ipvs</h2><p>修改ConfigMap的kube-system/kube-proxy中的config.conf，mode: “ipvs”：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl edit cm kube-proxy -n kube-system
</span></span><span class=line><span class=cl>configmap/kube-proxy edited
</span></span></code></pre></td></tr></table></div></div><p>之后重启各个节点上的kube-proxy pod：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get pod -n kube-system | grep kube-proxy | awk &#39;{system(&#34;kubectl delete pod &#34;$1&#34; -n kube-system&#34;)}&#39;
</span></span><span class=line><span class=cl>pod &#34;kube-proxy-2w9sh&#34; deleted
</span></span><span class=line><span class=cl>pod &#34;kube-proxy-gw4lx&#34; deleted
</span></span><span class=line><span class=cl>pod &#34;kube-proxy-thv4c&#34; deleted
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl get pod -n kube-system | grep kube-proxy
</span></span><span class=line><span class=cl>kube-proxy-6qlgv                        1/1     Running   0          65s
</span></span><span class=line><span class=cl>kube-proxy-fdtjd                        1/1     Running   0          47s
</span></span><span class=line><span class=cl>kube-proxy-m8zkx                        1/1     Running   0          52s
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>查看日志：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[centos@k8s-master ~]$ kubectl logs kube-proxy-6qlgv -n kube-system
</span></span><span class=line><span class=cl>I1213 09:50:15.414493       1 server_others.go:189] Using ipvs Proxier.
</span></span><span class=line><span class=cl>W1213 09:50:15.414908       1 proxier.go:365] IPVS scheduler not specified, use rr by default
</span></span><span class=line><span class=cl>I1213 09:50:15.415021       1 server_others.go:216] Tearing down inactive rules.
</span></span><span class=line><span class=cl>I1213 09:50:15.461658       1 server.go:464] Version: v1.13.0
</span></span><span class=line><span class=cl>I1213 09:50:15.467827       1 conntrack.go:52] Setting nf_conntrack_max to 131072
</span></span><span class=line><span class=cl>I1213 09:50:15.467997       1 config.go:202] Starting service config controller
</span></span><span class=line><span class=cl>I1213 09:50:15.468010       1 controller_utils.go:1027] Waiting for caches to sync for service config controller
</span></span><span class=line><span class=cl>I1213 09:50:15.468092       1 config.go:102] Starting endpoints config controller
</span></span><span class=line><span class=cl>I1213 09:50:15.468100       1 controller_utils.go:1027] Waiting for caches to sync for endpoints config controller
</span></span><span class=line><span class=cl>I1213 09:50:15.568766       1 controller_utils.go:1034] Caches are synced for endpoints config controller
</span></span><span class=line><span class=cl>I1213 09:50:15.568950       1 controller_utils.go:1034] Caches are synced for service config controller
</span></span><span class=line><span class=cl>[centos@k8s-master ~]$
</span></span></code></pre></td></tr></table></div></div><p>日志中打印出了Using ipvs Proxier，说明ipvs模式已经开启。</p><blockquote><p>由于本人初学kubernetes:以上是结合大白老师的文档实测安装成功,过程有曲折,但是肯定能安装成功;有问题可以问我。</p></blockquote></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2019-01-14</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/kubernetes/>Kubernetes</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/ class=prev rel=prev title=抽象工厂模式><i class="fas fa-angle-left fa-fw"></i>抽象工厂模式</a>
<a href=/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/ class=next rel=next title=原型设计模式>原型设计模式<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments></div></article></div></main><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2018 - 2024</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>yakax</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lightgallery.js@1.2.0/dist/css/lightgallery.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/algoliasearch@4.2.0/dist/algoliasearch-lite.umd.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery.js@1.2.0/dist/js/lightgallery.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lg-zoom.js@1.2.0/dist/lg-zoom.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/typeit@7.0.4/dist/typeit.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:10},comment:{},data:{"id-1":"yakax.blog","id-2":"yakax.blog"},lightGallery:{actualSize:!1,exThumbImage:"data-thumbnail",hideBarsDelay:2e3,selector:".lightgallery",speed:400,thumbContHeight:80,thumbWidth:80,thumbnail:!0},search:{algoliaAppID:"3MT6GW9D7W",algoliaIndex:"blog",algoliaSearchKey:"41ebe3571ca584723e8648600bbf45ce",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:150,type:"algolia"},typeit:{cursorChar:"_",cursorSpeed:1e3,data:{"id-1":["id-1"],"id-2":["id-2"]},duration:-1,speed:200}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>